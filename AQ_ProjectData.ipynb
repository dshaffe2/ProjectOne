{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: For the code to work, you must change the directory below in the glob.glob line\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2017.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2016.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2015.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2014.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2013.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2012.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2011.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2010.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2009.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2008.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2007.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2006.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2005.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2004.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2003.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2002.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2001.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_2000.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_1999.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_1998.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_1997.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_1996.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_1995.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_1994.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_1993.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_1992.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_1991.csv  \n",
      "Archive:  temp.zip\n",
      "  inflating: daily_aqi_by_cbsa_1990.csv  \n"
     ]
    }
   ],
   "source": [
    "#This only needs to be executed once, then the files are on your local\n",
    "\n",
    "yr = 2017\n",
    "\n",
    "while yr > 1989:\n",
    "    url = f'https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_cbsa_{yr}.zip'\n",
    "    response = requests.get(url)\n",
    "    yr -= 1\n",
    "    with open('temp.zip', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "        !unzip 'temp.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: 1990, 27 to go\n",
      "file: 1991, 26 to go\n",
      "file: 1992, 25 to go\n",
      "file: 1993, 24 to go\n",
      "file: 1994, 23 to go\n",
      "file: 1995, 22 to go\n",
      "file: 1996, 21 to go\n",
      "file: 1997, 20 to go\n",
      "file: 1998, 19 to go\n",
      "file: 1999, 18 to go\n",
      "file: 2000, 17 to go\n",
      "file: 2001, 16 to go\n",
      "file: 2002, 15 to go\n",
      "file: 2003, 14 to go\n",
      "file: 2004, 13 to go\n",
      "file: 2005, 12 to go\n",
      "file: 2006, 11 to go\n",
      "file: 2007, 10 to go\n",
      "file: 2008, 9 to go\n",
      "file: 2009, 8 to go\n",
      "file: 2010, 7 to go\n",
      "file: 2011, 6 to go\n",
      "file: 2012, 5 to go\n",
      "file: 2013, 4 to go\n",
      "file: 2014, 3 to go\n",
      "file: 2015, 2 to go\n",
      "file: 2016, 1 to go\n",
      "file: 2017, 0 to go\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "x = 27\n",
    "\n",
    "for file in glob.glob('C:/Users/dshaf/Documents/School/classproject/ProjectOne/Project Data/daily*'):\n",
    "\n",
    "    data = pd.read_csv(file, header = 0)\n",
    "    df = df.append(data)\n",
    "    print('file: ' + str(file[-8:-4]) + ', ' + str(x) + ' to go')\n",
    "    x -= 1\n",
    "    \n",
    "atlanta_df = df.loc[  (df['CBSA'].apply( lambda s:  \"Atlanta\" in s  )) & (df['Defining Parameter'] == 'Ozone')]\n",
    "dallas_df = df.loc[  (df['CBSA'].apply( lambda s:  \"Dallas\" in s  )) & (df['Defining Parameter'] == 'Ozone')]\n",
    "austin_df = df.loc[  (df['CBSA'].apply( lambda s:  \"Austin\" in s  )) & (df['Defining Parameter'] == 'Ozone')]\n",
    "nashville_df = df.loc[  (df['CBSA'].apply( lambda s:  \"Nashville\" in s  )) & (df['Defining Parameter'] == 'Ozone')]\n",
    "combined_df = df.loc[((df['CBSA'].apply( lambda s:  \"Atlanta\" in s  )) | (df['CBSA'].apply( lambda s:  \"Dallas\" in s  )) | (df['CBSA'].apply( lambda s:  \"Nashville\" in s  )) | (df['CBSA'].apply( lambda s:  \"Austin\" in s  ))) & (df['Defining Parameter'] == 'Ozone')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
